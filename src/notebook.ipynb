{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"../data/\"\n",
    "!ls $DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PICKLE_PRICE = \"../storage/thesis-gan/ywbjynma/preds_epoch=109-target_price=mid_price-target_volume=None.pickle\"\n",
    "PATH_PICKLE_VOLUME = \"../storage/thesis-gan/3chof3p2/preds_epoch=118-target_price=None-target_volume=volume.pickle\"\n",
    "PATH_PICKLE_REAL = \"../storage/thesis-gan/reals.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PICKLE_PIPELINE_PRICE = (\n",
    "    \"../storage/thesis-gan/ywbjynma/checkpoints/epoch=109-step=30799.ckpt/metadata/data_pipeline.pickle\"\n",
    ")\n",
    "PATH_PICKLE_PIPELINE_VOLUME = (\n",
    "    \"../storage/thesis-gan/3chof3p2/checkpoints/epoch=118-step=33319.ckpt/metadata/data_pipeline.pickle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_PICKLE_PRICE, \"rb\") as handle:\n",
    "    pred_prices_dict = pickle.load(handle)\n",
    "with open(PATH_PICKLE_VOLUME, \"rb\") as handle:\n",
    "    pred_volumes_dict = pickle.load(handle)\n",
    "with open(PATH_PICKLE_REAL, \"rb\") as handle:\n",
    "    reals_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_PICKLE_PIPELINE_PRICE, \"rb\") as handle:\n",
    "    pipeline_price = pickle.load(handle)\n",
    "with open(PATH_PICKLE_PIPELINE_VOLUME, \"rb\") as handle:\n",
    "    pipeline_volume = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_price, pipeline_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prices_dict.keys(), pred_volumes_dict.keys(), reals_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sequence_price = pred_prices_dict[\"pred_sequence\"]\n",
    "pred_prices = pred_prices_dict[\"pred_prices\"]\n",
    "prices = reals_dict[\"prices\"]\n",
    "pred_sequence_price.shape, pred_prices.shape, prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sequence_volume = pred_volumes_dict[\"pred_sequence\"]\n",
    "pred_volumes = pred_volumes_dict[\"pred_volumes\"]\n",
    "volumes = reals_dict[\"volumes\"]\n",
    "pred_sequence_volume.shape, pred_volumes.shape, volumes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = reals_dict[\"sequence\"]\n",
    "sequence_price = sequence[:, :4, :]\n",
    "sequence_volume = sequence[:, 4:, :]\n",
    "sequence_price.shape, sequence_volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_names = [\"KO\", \"PEP\", \"NVDA\", \"KSU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_price = sequence_price.squeeze().numpy().T\n",
    "pred_sequence_price = pred_sequence_price.squeeze().numpy().T\n",
    "prices = prices.squeeze().numpy().T\n",
    "pred_prices = pred_prices.squeeze().numpy().T\n",
    "sequence_price.shape, pred_sequence_price.shape, prices.shape, pred_prices.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_volume = sequence_volume.squeeze().numpy().T\n",
    "pred_sequence_volume = pred_sequence_volume.squeeze().numpy().T\n",
    "volumes = volumes.squeeze().numpy().T\n",
    "pred_volumes = pred_volumes.squeeze().numpy().T\n",
    "sequence_volume.shape, pred_sequence_volume.shape, volumes.shape, pred_volumes.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_price.shape, pred_sequence_price.shape, prices.shape, sequence_volume.shape, volumes.shape, pred_sequence_volume.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_indexes = np.arange(390)\n",
    "continuation_indexes = np.arange(390, prices.shape[0])\n",
    "history_indexes.shape, continuation_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = sequence_price[:390, :].T\n",
    "reals = sequence_price[390:, :].T\n",
    "preds = pred_sequence_price[390:, :].T\n",
    "history.shape, reals.shape, preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_and_reals = np.concatenate((history, reals), axis=1)\n",
    "history_and_preds = np.concatenate((history, preds), axis=1)\n",
    "history_and_reals.shape, history_and_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(20, 15))\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=\"C0\", lw=2, label=\"Observed\"),\n",
    "    Line2D([0], [0], color=\"C1\", lw=2, label=\"Real continuation\"),\n",
    "    Line2D([0], [0], color=\"C2\", lw=2, label=\"Predicted continuation\"),\n",
    "]\n",
    "\n",
    "ax[0, 0].set_title(f\"{stock_names[0]} - Volume\")\n",
    "ax[0, 0].plot(\n",
    "    history_indexes,\n",
    "    volumes[:390, 0],\n",
    "    color=\"C0\",\n",
    ")\n",
    "ax[0, 0].plot(\n",
    "    continuation_indexes,\n",
    "    volumes[390:, 0],\n",
    "    color=\"C1\",\n",
    ")\n",
    "ax[0, 0].plot(\n",
    "    continuation_indexes,\n",
    "    pred_volumes[390:, 0],\n",
    "    color=\"C2\",\n",
    ")\n",
    "\n",
    "ax[0, 1].set_title(f\"{stock_names[1]} - Volume\")\n",
    "ax[0, 1].plot(\n",
    "    history_indexes,\n",
    "    volumes[:390, 1],\n",
    "    color=\"C0\",\n",
    ")\n",
    "ax[0, 1].plot(\n",
    "    continuation_indexes,\n",
    "    volumes[390:, 1],\n",
    "    color=\"C1\",\n",
    ")\n",
    "ax[0, 1].plot(\n",
    "    continuation_indexes,\n",
    "    pred_volumes[390:, 1],\n",
    "    color=\"C2\",\n",
    ")\n",
    "\n",
    "ax[1, 0].set_title(f\"{stock_names[2]} - Volume\")\n",
    "ax[1, 0].plot(\n",
    "    history_indexes,\n",
    "    volumes[:390, 2],\n",
    "    color=\"C0\",\n",
    ")\n",
    "ax[1, 0].plot(\n",
    "    continuation_indexes,\n",
    "    volumes[390:, 2],\n",
    "    color=\"C1\",\n",
    ")\n",
    "ax[1, 0].plot(\n",
    "    continuation_indexes,\n",
    "    pred_volumes[390:, 2],\n",
    "    color=\"C2\",\n",
    ")\n",
    "\n",
    "ax[1, 1].set_title(f\"{stock_names[3]} - Volume\")\n",
    "ax[1, 1].plot(\n",
    "    history_indexes,\n",
    "    volumes[:390, 3],\n",
    "    color=\"C0\",\n",
    ")\n",
    "ax[1, 1].plot(\n",
    "    continuation_indexes,\n",
    "    volumes[390:, 3],\n",
    "    color=\"C1\",\n",
    ")\n",
    "ax[1, 1].plot(\n",
    "    continuation_indexes,\n",
    "    pred_volumes[390:, 3],\n",
    "    color=\"C2\",\n",
    ")\n",
    "\n",
    "fig.legend(handles=legend_elements, loc=\"upper center\", ncol=3)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"/Users/giuseppemasi/PycharmProjects/thesis-gan/storage/thesis-gan/volumes.png\")\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_avg_log_returns = compute_avg_log_returns(sequence_price, 15)\n",
    "real_avg_volumes = compute_avg_volumes(sequence_volume, 15)\n",
    "\n",
    "pred_avg_log_returns = compute_avg_log_returns(pred_sequence_price, 15)\n",
    "pred_avg_volumes = compute_avg_volumes(pred_sequence_volume, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(7 * 4, 10))\n",
    "\n",
    "for target_idx in range(4):\n",
    "    stock_name = stock_names[target_idx]\n",
    "\n",
    "    # Real volume-volatility correlation\n",
    "    title = f\"{stock_name} - Real\"\n",
    "    ax[0, target_idx].set_title(title)\n",
    "    ax[0, target_idx].scatter(\n",
    "        real_avg_log_returns[target_idx],\n",
    "        real_avg_volumes[target_idx],\n",
    "        color=\"C0\",\n",
    "    )\n",
    "    ax[0, target_idx].set_xlabel(\"Avg log-returns\")\n",
    "    ax[0, target_idx].set_ylabel(\"Avg log-volumes\")\n",
    "\n",
    "    # Pred volume-volatility correlation\n",
    "    title = f\"{stock_name} - Pred\"\n",
    "    ax[1, target_idx].set_title(title)\n",
    "    ax[1, target_idx].scatter(\n",
    "        pred_avg_log_returns[target_idx],\n",
    "        pred_avg_volumes[target_idx],\n",
    "        color=\"C1\",\n",
    "    )\n",
    "    ax[1, target_idx].set_xlabel(\"Avg log-returns\")\n",
    "    ax[1, target_idx].set_ylabel(\"Avg log-volumes\")\n",
    "\n",
    "fig.tight_layout()\n",
    "title = \"Volume-Volatility Corr\"\n",
    "# plt.show()\n",
    "plt.savefig(f\"/home/giuseppe/PycharmProjects/thesis-gan/storage/thesis-gan/{title}.png\")\n",
    "\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(os.path.join(DATA, \"volumes_metrics\", \"*.csv\"))\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), axis=1, ignore_index=False)\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWEEPNAME = \"stoic-jazz-65\"\n",
    "STOCK_NAMES = [\"PEP\", \"KO\", \"KSU\", \"NVDA\"]\n",
    "METRIC_NAMES = [\"Max\", \"Skew\", \"Min\", \"Mean\", \"Std\", \"Kurtosis\"]\n",
    "REAL_PRED = [\"Real\", \"Pred\"]\n",
    "COLUMNS = [\n",
    "    SWEEPNAME + \" - \" + realOpred + \" Volume: \" + metric_name + \"/\" + stock_name + \"_epoch\"\n",
    "    for stock_name in STOCK_NAMES\n",
    "    for metric_name in METRIC_NAMES\n",
    "    for realOpred in REAL_PRED\n",
    "]\n",
    "COLUMNS.insert(0, \"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[COLUMNS].iloc[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv(os.path.join(DATA, \"volume_quality_metrics.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_volume_corr_dist = pd.read_csv(os.path.join(DATA, \"avg_volume_corr_dist.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = [\n",
    "    \"KO_volume-KSU_volume_epoch\",\n",
    "    \"KO_volume-NVDA_volume_epoch\",\n",
    "    \"KO_volume-PEP_volume_epoch\",\n",
    "    \"NVDA_volume-KSU_volume_epoch\",\n",
    "    \"PEP_volume-KSU_volume_epoch\",\n",
    "    \"PEP_volume-NVDA_volume_epoch\",\n",
    "]\n",
    "COLUMNS = [SWEEPNAME + \" - corr_dist/\" + col for col in COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_volume_corr_dist[COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_volume_corr_dist[COLUMNS]\n",
    "df_avg_volume_corr_dist[\"avg\"] = df_avg_volume_corr_dist[COLUMNS].mean(axis=1)\n",
    "print(df_avg_volume_corr_dist[COLUMNS].iloc[65])\n",
    "print(df_avg_volume_corr_dist[[\"avg\"]].iloc[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA + \"ohlc_KO_PEP_NVDA_KSU_train.csv\")\n",
    "df_val = pd.read_csv(DATA + \"ohlc_KO_PEP_NVDA_KSU_val.csv\")\n",
    "df = pd.concat([df_train, df_val])\n",
    "# print(df.columns)\n",
    "df = df.drop(\n",
    "    [\n",
    "        \"hour_slot\",\n",
    "        \"minute_slot\",\n",
    "        \"weekday\",\n",
    "        \"symbol\",\n",
    "        \"open_KO\",\n",
    "        \"high_KO\",\n",
    "        \"low_KO\",\n",
    "        \"norders_KO\",\n",
    "        \"mid_price_KO\",\n",
    "        \"open_PEP\",\n",
    "        \"high_PEP\",\n",
    "        \"low_PEP\",\n",
    "        \"norders_PEP\",\n",
    "        \"mid_price_PEP\",\n",
    "        \"open_NVDA\",\n",
    "        \"high_NVDA\",\n",
    "        \"low_NVDA\",\n",
    "        \"norders_NVDA\",\n",
    "        \"mid_price_NVDA\",\n",
    "        \"open_KSU\",\n",
    "        \"high_KSU\",\n",
    "        \"low_KSU\",\n",
    "        \"norders_KSU\",\n",
    "        \"mid_price_KSU\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "# print(df.columns)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_v = [\"volume_KO\", \"volume_PEP\", \"volume_NVDA\", \"volume_KSU\"]\n",
    "\n",
    "targets_p = [\"mid_price_KO\", \"mid_price_PEP\", \"mid_price_NVDA\", \"mid_price_KSU\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[targets_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "\n",
    "def is_fitted(scaler: Union[MinMaxScaler, StandardScaler]) -> bool:\n",
    "    try:\n",
    "        check_is_fitted(scaler)\n",
    "        return True\n",
    "    except NotFittedError:\n",
    "        return False\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        pass\n",
    "\n",
    "    def preprocess(self, df: pd.DataFrame, targets: List[str]) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def inverse_transform(self, x: np.ndarray, x_last: Optional[np.ndarray]) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__} (scaler={self.scaler})\"\n",
    "\n",
    "\n",
    "class ScalerPipeline(Pipeline):\n",
    "    def __init__(self, scaler: Union[MinMaxScaler, StandardScaler]) -> None:\n",
    "        super(ScalerPipeline, self).__init__()\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def preprocess(self, df: pd.DataFrame, targets: List[str]) -> np.ndarray:\n",
    "        df_targets = df[targets]\n",
    "\n",
    "        if not is_fitted(self.scaler):\n",
    "            self.scaler.fit(df_targets)\n",
    "\n",
    "        return self.scaler.transform(df_targets)\n",
    "\n",
    "    def inverse_transform(self, x: np.ndarray, x_last: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "        return self.scaler.inverse_transform(x)\n",
    "\n",
    "\n",
    "class LogReturnPipeline(Pipeline):\n",
    "    def __init__(self, scaler: Union[MinMaxScaler, StandardScaler]) -> None:\n",
    "        super(LogReturnPipeline, self).__init__()\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def preprocess(self, df: pd.DataFrame, targets: List[str]) -> np.ndarray:\n",
    "        df_targets = df[targets]\n",
    "        log_returns = np.log(df_targets / df_targets.shift(1)).fillna(0).to_numpy()\n",
    "\n",
    "        if not is_fitted(self.scaler):\n",
    "            self.scaler.fit(log_returns)\n",
    "\n",
    "        return self.scaler.transform(log_returns)\n",
    "\n",
    "    def inverse_transform(self, x: np.ndarray, x_last: np.ndarray) -> np.ndarray:\n",
    "        log_returns = self.scaler.inverse_transform(x)\n",
    "        return x_last * (np.cumprod(np.exp(log_returns), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCKS = [\"KO\", \"PEP\", \"NVDA\", \"KSU\"]\n",
    "log_return_pipeline = LogReturnPipeline(StandardScaler())\n",
    "df_train_pre = pd.DataFrame(log_return_pipeline.preprocess(df_train, targets_p), columns=STOCKS)\n",
    "df_val_pre = pd.DataFrame(log_return_pipeline.preprocess(df_val, targets_p), columns=STOCKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_val_pre.corr(numeric_only=True)\n",
    "sb.heatmap(corr, cmap=\"Blues\", annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
