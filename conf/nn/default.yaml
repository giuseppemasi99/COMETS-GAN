target_feature: close
stock_names: [KO, PEP, NVDA, KSU]

data:
  _target_: thesis_gan.data.datamodule.MyDataModule

  data_pipeline:
    _target_: thesis_gan.data.pipeline.LogReturnPipeline
    scaler:
      _target_: sklearn.preprocessing.StandardScaler

  datasets:
    train:
      _target_: thesis_gan.data.dataset.StockDataset
      path: ${oc.env:PROJECT_ROOT}/data/ohlc_KO_PEP_NVDA_KSU_train.csv
      target_feature: ${nn.target_feature}
      stock_names: ${nn.stock_names}
      encoder_length: 390
      decoder_length: 150
      stride: 1


    val:
      - _target_: thesis_gan.data.dataset.StockDataset
        path: ${oc.env:PROJECT_ROOT}/data/ohlc_KO_PEP_NVDA_KSU_val.csv
        target_feature: ${nn.target_feature}
        stock_names: ${nn.stock_names}
        encoder_length: 390
        decoder_length: 150
        stride: 1

    test:
      - _target_: thesis_gan.data.dataset.StockDataset
        path: ${oc.env:PROJECT_ROOT}/data/ohlc_KO_PEP_NVDA_KSU_test.csv
        target_feature: ${nn.target_feature}
        stock_names: ${nn.stock_names}
        encoder_length: 390
        decoder_length: 150
        stride: 1

  gpus: ${train.trainer.gpus}

  num_workers:
    train: 12
    val: 12
    test: 12

  batch_size:
    train: 128
    val: 128
    test: 128

module:
  _target_: thesis_gan.pl_modules.pl_module.MyLightningModule

  optimizer_g:
    _target_: torch.optim.RMSprop
    lr: 1e-4

  optimizer_d:
    _target_: torch.optim.RMSprop
    lr: 3e-4

  stock_names: ${nn.stock_names}
  encoder_length: 390
  decoder_length: 150
  gen_hidden_dim: 256
  disc_hidden_dim: 256
  n_critic: 5
  dropout: 0.2
  compute_corr: True
  val_log_freq: 5

#  lr_scheduler:
#    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
#    T_0: 10
#    T_mult: 2
#    eta_min: 0 # min value for the lr
#    last_epoch: -1
#    verbose: False
